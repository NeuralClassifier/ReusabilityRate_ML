{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niAd-DB0VoTX"
      },
      "source": [
        "## Reqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lREROh-YV7QE",
        "outputId": "7ae9c855-59d1-4d98-868a-14b22545b284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9m7LcF9WErj",
        "outputId": "0a01a54a-fdf5-441a-dca7-3ba2abfdae4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ReusabilityRate_ML'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 80 (delta 26), reused 7 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/ReusabilityRate_ML/DataSets\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NeuralClassifier/ReusabilityRate_ML\n",
        "!git checkout corr_analysis\n",
        "%cd /content/ReusabilityRate_ML/DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8L9SOrFdVjrI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statistics\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ll3IsmWdzx"
      },
      "source": [
        "### Read class and package metrics(x:inputs) and RR(y:label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pdqaGed7WP35"
      },
      "outputs": [],
      "source": [
        "cls_df = pd.read_excel('classes.xlsx')\n",
        "pkg_df = pd.read_excel('packages.xlsx')\n",
        "cls_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "pkg_df.drop(['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0K3nWh_VpUf"
      },
      "source": [
        "## Class DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Do9iLiXH-9"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe0kNtzAVm5x",
        "outputId": "62033528-014b-48dc-f975-7c8d3a0fdd0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MinMaxScaler(feature_range=(-10, 10))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "data = cls_df\n",
        "df = data.iloc[:,3:-1]\n",
        "data_columns = df.columns\n",
        "X_np = np.array(df)\n",
        "target_scaler.fit(X_np)\n",
        "X = X_np\n",
        "#X = target_scaler.transform(X_np)\n",
        "\n",
        "Y = data.iloc[:,-1]\n",
        "Y = Y.values.reshape(-1, 1)\n",
        "target_scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "target_scaler.fit(Y)\n",
        "#Y = target_scaler.transform(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbOMbAO4ideh"
      },
      "source": [
        "### Training data preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8kbRzMLmfI1G"
      },
      "outputs": [],
      "source": [
        "#indexes = np.arange(len(X))\n",
        "splitter = int(len(X) * .8)\n",
        "X_train = X[:splitter]\n",
        "Y_train = Y[:splitter]\n",
        "X_val = X[splitter:]\n",
        "Y_val = Y[splitter:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzLMFnPi94Nj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBOVUH0YW_HW"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYsVRaQmXBZ8",
        "outputId": "ba07daa8-e4d4-4079-cdf9-b44ca1ba5d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 27)]              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 100)               2800      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,151\n",
            "Trainable params: 9,151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "##model\n",
        "\n",
        "\n",
        "def my_model_fully_connected(loss_fn, opt, ishape = 27, lr = 1e-2):\n",
        "    model_input = tf.keras.layers.Input(shape = ishape)\n",
        "    l2 = tf.keras.layers.Dense(100, activation = 'relu')(model_input)\n",
        "    l2_drop = tf.keras.layers.Dropout(0.05)(l2)\n",
        "    l3 = tf.keras.layers.Dense(50, activation = 'relu')(l2_drop)\n",
        "    l4 = tf.keras.layers.Dense(25, activation = 'relu')(l3) \n",
        "    out= tf.keras.layers.Dense(1, activation = 'relu')(l4)\n",
        "    model = tf.keras.models.Model(inputs = model_input, outputs = out)\n",
        "    model.compile(optimizer=opt, loss=loss_fn, metrics = [\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "lr = 0.0001\n",
        "opt = opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "loss_fn = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "model = my_model_fully_connected(loss_fn, opt, ishape=len(X_train[0]), lr= lr)\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GlbWYmXDLEh",
        "outputId": "e57fd16c-6e74-4e4c-e8fa-5609860e9c91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  6],\n",
              "       [  4],\n",
              "       [  6],\n",
              "       [122],\n",
              "       [ 82],\n",
              "       [167],\n",
              "       [ 18],\n",
              "       [  0],\n",
              "       [  3],\n",
              "       [  1],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [  0],\n",
              "       [ 29],\n",
              "       [  0],\n",
              "       [  6],\n",
              "       [  0],\n",
              "       [  1],\n",
              "       [  0]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NrIO_556XC9Y"
      },
      "outputs": [],
      "source": [
        "# Call backs \n",
        "model_name_fcn = \"First_draft.h5\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 200)\n",
        "\n",
        "monitor = tf.keras.callbacks.ModelCheckpoint(model_name_fcn, monitor='val_loss',\\\n",
        "                                             verbose=0, save_best_only=True,\\\n",
        "                                             save_weights_only=True,\\\n",
        "                                             mode='min')\n",
        "# Learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch%10 == 0:\n",
        "        lr = lr\n",
        "    return lr\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQK6eaFC47Mt",
        "outputId": "090b437f-c8c9-4420-c0d7-88e8fd92e4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.1184 - accuracy: 0.7142 - val_loss: 1.1027 - val_accuracy: 0.7481 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.1048 - accuracy: 0.7158 - val_loss: 1.0956 - val_accuracy: 0.7479 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.1012 - accuracy: 0.7162 - val_loss: 1.0948 - val_accuracy: 0.7485 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.7163 - val_loss: 1.0948 - val_accuracy: 0.7481 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0988 - accuracy: 0.7161 - val_loss: 1.0948 - val_accuracy: 0.7481 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0964 - accuracy: 0.7161 - val_loss: 1.0943 - val_accuracy: 0.7465 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.7131 - val_loss: 1.0909 - val_accuracy: 0.7483 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.7164 - val_loss: 1.0904 - val_accuracy: 0.7481 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0934 - accuracy: 0.7163 - val_loss: 1.0908 - val_accuracy: 0.7471 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0417 - accuracy: 0.7065 - val_loss: 1.0816 - val_accuracy: 0.7423 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.2111 - accuracy: 0.6737 - val_loss: 1.0879 - val_accuracy: 0.7473 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0880 - accuracy: 0.7060 - val_loss: 1.0805 - val_accuracy: 0.7455 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0206 - accuracy: 0.6897 - val_loss: 1.0835 - val_accuracy: 0.7078 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.9872 - accuracy: 0.6660 - val_loss: 0.9483 - val_accuracy: 0.6880 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.7626 - accuracy: 0.6298 - val_loss: 1.2795 - val_accuracy: 0.3652 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6006 - val_loss: 0.7468 - val_accuracy: 0.5568 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.5895 - val_loss: 0.7634 - val_accuracy: 0.5422 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.5902 - val_loss: 0.7376 - val_accuracy: 0.5435 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.5925 - val_loss: 0.7616 - val_accuracy: 0.4253 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.5877 - val_loss: 0.8023 - val_accuracy: 0.3987 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.5877 - val_loss: 0.7407 - val_accuracy: 0.5187 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.5918 - val_loss: 0.7633 - val_accuracy: 0.5850 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.5940 - val_loss: 0.8432 - val_accuracy: 0.4283 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.5917 - val_loss: 0.8299 - val_accuracy: 0.4110 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.5947 - val_loss: 0.7541 - val_accuracy: 0.4757 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.5924 - val_loss: 1.0949 - val_accuracy: 0.2791 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.5906 - val_loss: 0.7395 - val_accuracy: 0.4987 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.5943 - val_loss: 0.8913 - val_accuracy: 0.3291 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.5931 - val_loss: 0.7399 - val_accuracy: 0.4684 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.5912 - val_loss: 0.9944 - val_accuracy: 0.3325 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.5964 - val_loss: 0.9692 - val_accuracy: 0.3573 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.5966 - val_loss: 0.7397 - val_accuracy: 0.4793 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.5956 - val_loss: 0.7516 - val_accuracy: 0.5334 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.5964 - val_loss: 0.8935 - val_accuracy: 0.3416 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.5955 - val_loss: 0.7570 - val_accuracy: 0.5749 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.5982 - val_loss: 0.7236 - val_accuracy: 0.5146 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.5955 - val_loss: 0.7754 - val_accuracy: 0.4241 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.5950 - val_loss: 0.8488 - val_accuracy: 0.3563 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.5954 - val_loss: 0.7550 - val_accuracy: 0.4775 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.6001 - val_loss: 0.7677 - val_accuracy: 0.4477 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.5996 - val_loss: 0.7264 - val_accuracy: 0.4896 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.5998 - val_loss: 0.7597 - val_accuracy: 0.5090 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.5981 - val_loss: 0.7335 - val_accuracy: 0.5638 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.6003 - val_loss: 0.7326 - val_accuracy: 0.4856 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.6006 - val_loss: 0.8045 - val_accuracy: 0.4140 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.5998 - val_loss: 1.0628 - val_accuracy: 0.3126 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.5999 - val_loss: 0.7696 - val_accuracy: 0.6483 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.6017 - val_loss: 0.9474 - val_accuracy: 0.3317 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.5988 - val_loss: 0.7368 - val_accuracy: 0.5715 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.6020 - val_loss: 1.1271 - val_accuracy: 0.3406 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.6026 - val_loss: 0.7323 - val_accuracy: 0.5297 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.6036 - val_loss: 0.7285 - val_accuracy: 0.5378 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.6039 - val_loss: 0.7435 - val_accuracy: 0.4868 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.5982 - val_loss: 0.7668 - val_accuracy: 0.5049 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.6042 - val_loss: 0.7439 - val_accuracy: 0.4793 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.6020 - val_loss: 0.8221 - val_accuracy: 0.3890 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.6003 - val_loss: 0.7285 - val_accuracy: 0.6033 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.6035 - val_loss: 0.7792 - val_accuracy: 0.4574 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.6050 - val_loss: 0.7578 - val_accuracy: 0.4813 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.6044 - val_loss: 0.7927 - val_accuracy: 0.4257 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.6016 - val_loss: 0.8998 - val_accuracy: 0.3597 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.6003 - val_loss: 0.9434 - val_accuracy: 0.3402 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.6032 - val_loss: 0.7624 - val_accuracy: 0.5495 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.6010 - val_loss: 0.7309 - val_accuracy: 0.5241 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.6042 - val_loss: 1.4968 - val_accuracy: 0.2136 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.6059 - val_loss: 0.7334 - val_accuracy: 0.5213 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.6037 - val_loss: 0.7383 - val_accuracy: 0.5136 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.6069 - val_loss: 0.7423 - val_accuracy: 0.4828 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.6017 - val_loss: 0.7702 - val_accuracy: 0.4567 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.6035 - val_loss: 0.7460 - val_accuracy: 0.5991 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.6054 - val_loss: 0.8240 - val_accuracy: 0.6487 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.6044 - val_loss: 0.7372 - val_accuracy: 0.5174 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.6026 - val_loss: 0.7292 - val_accuracy: 0.5303 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.6049 - val_loss: 0.7387 - val_accuracy: 0.4799 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.6033 - val_loss: 0.7827 - val_accuracy: 0.4434 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.6050 - val_loss: 0.7362 - val_accuracy: 0.5497 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.6053 - val_loss: 0.7416 - val_accuracy: 0.5021 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.6034 - val_loss: 0.8706 - val_accuracy: 0.3783 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.6056 - val_loss: 0.9679 - val_accuracy: 0.2954 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.6056 - val_loss: 0.7455 - val_accuracy: 0.5084 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.6064 - val_loss: 0.7435 - val_accuracy: 0.5552 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.6049 - val_loss: 0.9152 - val_accuracy: 0.3721 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.6041 - val_loss: 0.7489 - val_accuracy: 0.4860 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.6077 - val_loss: 0.7567 - val_accuracy: 0.6138 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.6082 - val_loss: 0.8066 - val_accuracy: 0.3844 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.6040 - val_loss: 0.7558 - val_accuracy: 0.4928 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.6054 - val_loss: 0.7359 - val_accuracy: 0.5322 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.6100 - val_loss: 0.7362 - val_accuracy: 0.5703 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.6036 - val_loss: 1.0586 - val_accuracy: 0.3025 - lr: 0.0100\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.6062 - val_loss: 0.7410 - val_accuracy: 0.5876 - lr: 0.0100\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.6091 - val_loss: 0.7671 - val_accuracy: 0.6207 - lr: 0.0100\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.6121 - val_loss: 0.8026 - val_accuracy: 0.4426 - lr: 0.0100\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.6057 - val_loss: 0.7834 - val_accuracy: 0.5880 - lr: 0.0100\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.6019 - val_loss: 0.7374 - val_accuracy: 0.4985 - lr: 0.0100\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.6109 - val_loss: 0.7292 - val_accuracy: 0.5011 - lr: 0.0100\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.6071 - val_loss: 0.7863 - val_accuracy: 0.6134 - lr: 0.0100\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.6034 - val_loss: 0.7416 - val_accuracy: 0.5279 - lr: 0.0100\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.6078 - val_loss: 0.7418 - val_accuracy: 0.5176 - lr: 0.0100\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.6097 - val_loss: 0.7763 - val_accuracy: 0.4334 - lr: 0.0100\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.6057 - val_loss: 0.8427 - val_accuracy: 0.3868 - lr: 0.0100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6dc7baff50>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train\n",
        "model.fit(X_train, Y_train, epochs = 100, batch_size=200, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule], validation_data= (X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq6EldoEMQNW",
        "outputId": "64f394cd-8e02-455b-c7d3-f4eb4e6cf592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[array([[0.]], dtype=float32), array([6])]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(str(len(X_train[0])))\n",
        "[model.predict(X_train[3].reshape([1,27])), Y_train[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyd2aa8mVrfi"
      },
      "source": [
        "## Package DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5nhMPMXYRz"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RLf0gtbvWxKC"
      },
      "outputs": [],
      "source": [
        "target_scaler = MinMaxScaler()\n",
        "data = pkg_df\n",
        "df = data.iloc[:,3:-1]\n",
        "data_columns = df.columns\n",
        "X_np = np.array(df)\n",
        "target_scaler.fit(X_np)\n",
        "X = target_scaler.transform(X_np)\n",
        "\n",
        "Y = data.iloc[:,-1]\n",
        "Y = Y.values.reshape(-1, 1)\n",
        "target_scaler = MinMaxScaler()\n",
        "target_scaler.fit(Y)\n",
        "Y = target_scaler.transform(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tgVoBmEAEMxU"
      },
      "outputs": [],
      "source": [
        "splitter = int(len(X) * .8)\n",
        "X_train = X[:splitter]\n",
        "Y_train = Y[:splitter]\n",
        "X_val = X[splitter:]\n",
        "Y_val = Y[splitter:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9tAB9YCXZ8p"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4QTYf2JESEg",
        "outputId": "2f35084f-0890-44dc-bc71-103dfea60809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 18)]              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 100)               1900      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,251\n",
            "Trainable params: 8,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def my_model_fully_connected(loss_fn, opt, ishape = 27, lr = 1e-2):\n",
        "    model_input = tf.keras.layers.Input(shape = ishape)\n",
        "    l2 = tf.keras.layers.Dense(100, activation = 'sigmoid')(model_input)\n",
        "    l2_drop = tf.keras.layers.Dropout(0.05)(l2)\n",
        "    l3 = tf.keras.layers.Dense(50, activation = 'relu')(l2_drop)\n",
        "    l4 = tf.keras.layers.Dense(25, activation = 'relu')(l3) \n",
        "    out= tf.keras.layers.Dense(1, activation = 'relu')(l4)\n",
        "    model = tf.keras.models.Model(inputs = model_input, outputs = out)\n",
        "    model.compile(optimizer=opt, loss=loss_fn, metrics = [\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "lr = 0.001\n",
        "opt = opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "loss_fn = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "model = my_model_fully_connected(loss_fn, opt, ishape=len(X_train[0]), lr= lr)\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4m9xcAk7EaYD"
      },
      "outputs": [],
      "source": [
        "model_name_fcn = \"package_draft.h5\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 200)\n",
        "\n",
        "monitor = tf.keras.callbacks.ModelCheckpoint(model_name_fcn, monitor='val_loss',\\\n",
        "                                             verbose=0, save_best_only=True,\\\n",
        "                                             save_weights_only=True,\\\n",
        "                                             mode='min')\n",
        "# Learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch%10 == 0:\n",
        "        lr = lr/2\n",
        "    return lr\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0VJVOdnxXcFJ",
        "outputId": "d8da5152-a7f5-45c2-8bf2-fa7f95a4cf8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.0238 - accuracy: 0.5251 - val_loss: 0.0109 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 2/100\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.5251 - val_loss: 0.0051 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 3/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.5251 - val_loss: 0.0027 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 4/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.5251 - val_loss: 0.0019 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 5/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 6/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 7/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 8/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 9/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 10/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 11/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 12/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 13/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.9698e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 14/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.5444e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 15/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.3873e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 16/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.0718e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 17/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.4879e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 18/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.8370e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 19/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.9530e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 20/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.5888e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 2.5000e-04\n",
            "Epoch 21/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.6820e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 1.2500e-04\n",
            "Epoch 22/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.6669e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 1.2500e-04\n",
            "Epoch 23/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.7975e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 1.2500e-04\n",
            "Epoch 24/100\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.7518e-04 - accuracy: 0.5251 - val_loss: 0.0017 - val_accuracy: 0.6082 - lr: 1.2500e-04\n",
            "Epoch 25/100\n",
            "37/55 [===================>..........] - ETA: 0s - loss: 6.4980e-04 - accuracy: 0.5160"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-44005d009e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## Train model\n",
        "model.fit(X_train, Y_train, epochs = 100, batch_size=32, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule], validation_data= (X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSG14H0HXdbP"
      },
      "outputs": [],
      "source": [
        "## Test model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "all_input_dnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
